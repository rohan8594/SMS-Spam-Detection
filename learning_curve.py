# File:        learning_curve.py
#
# Author:      Rohan Patel
#
# Date:        05/16/2018
#
# Description: This script plots a learning curve to evaluate our learned classifier. The learning 
#              curve is generated by plotting the error rate vs the training set size. It is used 
#              used to diagnose bias and variance and thereby diagnose whether our classifier shows
#              any underfitting or overfitting symptoms.

import pickle
import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt

def learning_curve(feature_vect, messages, folds):
	training_set_size = []
	train_error = []
	cv_error = []

	print("")
	print("This may take some time, please wait..", sep=' ', end='', flush=True)
	for training_size in range(10, len(messages), 75):
		print(".", sep=' ', end='', flush=True)
		X = feature_vect[:training_size]
		y = messages['label'][:training_size]
		kf = KFold(n_splits=folds, random_state=None, shuffle=False)
		err1 = []
		err2 = []

		# generate K folds and train classifier on every fold
		for train_index, test_index in kf.split(X):
			#print("TRAIN:", train_index, "TEST:", test_index)
			X_train, X_test = X[train_index], X[test_index]
			y_train, y_test = y[train_index], y[test_index]

			mnb = MultinomialNB(alpha = 0.10000000000000001)
			mnb.fit(X_train, y_train)
			pred = mnb.predict(X_test)

			err = 1.0 - (mnb.score(X_train,y_train))
			err1.append(err) # training error
			err = 1.0 - (mnb.score(X_test,y_test))
			err2.append(err) # cv error

		train_error.append(np.average(err1)) # training error =  avg of training error from every fold
		cv_error.append(np.average(err2))    # cross-validation error = avg of cv error from every fold
		training_set_size.append(training_size)

	# Plotting of learning curve using matplotlib
	x = training_set_size
	y = train_error
	z = cv_error

	fig = plt.figure(figsize=(10,5))
	plt.plot(x,y, label='Training error')
	plt.plot(x,z,'g-', label='Cross-Validation error')
	plt.xlabel('Training Set Size')
	plt.ylabel('Error Rate')
	plt.title('Learning Curve')
	plt.legend()
	plt.show(block = True)

def main():

	tfidf_vect = pickle.load(open("output/tfidf_vector.pickle", "rb")) # load previously generated tf-idf vector from pickle file
	messages = pd.read_csv('output/processed_msgs.csv')

	# append our message length feature to the tfidf vector to produce the final feature vector we fit into our classifiers
	len_feature = messages['length'].as_matrix()
	feat_vect = np.hstack((tfidf_vect.todense(), len_feature[:, None]))

	learning_curve(feat_vect, messages, folds = 5)
	#learning_curve(feat_vect, messages, folds = 10)

if __name__ == "__main__":
    main()